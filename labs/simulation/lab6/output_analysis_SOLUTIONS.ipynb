{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Simulation: Output Analysis\n",
    "\n",
    "When you have built your computer simulation model of the health system you need ensure that you are carefully analysing the results. Two important tasks are choosing the number of replications and selecting a warm-up period.  The latter is relevant for many stochastic health systems as they are **non-terminating**. \n",
    "\n",
    "**In the lab you will learn how to :**\n",
    "\n",
    "* how to perform multiple replications of a simulation model implemented in `simpy`.\n",
    "* how to estimate and use warm-up period of a non-terminating simulation model.\n",
    "* how to select the number of replications to run of a single scenario.\n",
    "* how to informally compare multiple competing scenarios\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "Please use the provided `hds_stoch` environment for this work.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install simpy~\n",
    "\n",
    "import simpy\n",
    "simpy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from scipy.stats import t\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import model classes\n",
    "\n",
    "The exercises in this class will make use of the `UrgentCareCallCentre` model.  A version of this model is available in the `hds_simpy` package included with this notebook. \n",
    "\n",
    "> In this case the package is a subdirectory called `hds_simpy`\n",
    "\n",
    "**As a reminder** the basic process in the model is:\n",
    "\n",
    "* A person who is unwell calls the urgent care centre\n",
    "* The call is initially handled by an operator. \n",
    "* A percentage of the calls require a callback from a nurse.\n",
    "* A person requiring a callback waits for the nurse to call back.\n",
    "\n",
    "The **key performance measures** of the model are:\n",
    "\n",
    "* Mean number of people in the queue for an operator and a nurse\n",
    "* The mean waiting time for an operator and a nurse.\n",
    "* The utilisation of the operators and the nurses\n",
    "\n",
    "> For simplicity we will focus our analysis on the latter two of these types of measure.  In practice you would be required to analyse all of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hds_simpy.models.UrgentCareCallCentre import (UrgentCareCallCentre, \n",
    "                                                   Scenario,\n",
    "                                                   single_run,\n",
    "                                                   multiple_replications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Test a single run of the model\n",
    "\n",
    "**Task**\n",
    "* Run the code below to perform a single run of the model.\n",
    "* Try changing `random_no_set` parameter of `single_run` to see different results\n",
    "* **Optional**: navigate to `hds_simpy/models/UrgentCareCallCentre` and read the code for `single_run()`\n",
    "\n",
    "**Questions**\n",
    "* How you would intutively go about implementing multiple replications given this function?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the default scenario\n",
    "args = Scenario()\n",
    "\n",
    "#use the single_run() func\n",
    "#try changing `random_no_set` to see different run results\n",
    "print('Running simulation ...', end=' => ')\n",
    "results = single_run(args, random_no_set=42)\n",
    "print('simulation complete.')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Multiple replications of the model\n",
    "\n",
    "**Task:**\n",
    "* Read and run the code below.\n",
    "* Try changing the number of replications (e.g. 10 or 20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default scenario\n",
    "args = Scenario()\n",
    "\n",
    "#run multiple replications.\n",
    "#by default it runs 5 replications.\n",
    "print('Running multiple replications', end=' => ')\n",
    "results  = multiple_replications(args, n_reps=5)\n",
    "print('done.\\n')\n",
    "\n",
    "#show reps rounded to 2dp\n",
    "results.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Graphical plots of the replications\n",
    "\n",
    "To understand the spread of your replication results it is sometimes useful to plot a histogram.\n",
    "\n",
    "**Task**\n",
    "* Run 50 replications of the model\n",
    "* Plot a histogram of the `nurse_queue` and `operator_wait` variables.\n",
    "\n",
    "**Hints**:\n",
    "* To plot a histogram you can use the following code:\n",
    "\n",
    "```python\n",
    "#results is a dataframe returned from the multi reps func\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12,4))\n",
    "ax[0].hist(results['nurse_queue']);\n",
    "ax[1].hist(results['operator_wait']);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Scenario()\n",
    "\n",
    "#run multiple replications.\n",
    "#by default it runs 5 replications.\n",
    "print('Running multiple replications', end=' => ')\n",
    "results  = multiple_replications(args, n_reps=50)\n",
    "print('done.\\n')\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12,4))\n",
    "ax[0].hist(results['nurse_queue']);\n",
    "ax[0].set_ylabel('nurse_queue')\n",
    "ax[1].hist(results['operator_wait']);\n",
    "ax[1].set_ylabel('operator_wait');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Coding your own multiple replications function.\n",
    "\n",
    "Here is where the benefit of using functions to organise your experimentation really pays off!  To perform multiple replications we just need to call `single_run` multiple times in a loop.\n",
    "\n",
    "**Task**:\n",
    "\n",
    "* Complete function below called `my_multiple_replications`.  \n",
    "* The function should accept the following parameters:\n",
    "   * scenario: `Scenario` - Parameters/arguments to configure the model\n",
    "   * rc_period: `int` (default=1440) - the results collection period. i.e. the minutes to run the model in simulated time beyond the warmup period.\n",
    "   * warm_up: the warm up period of the model where no results are collected.  This should be optional.  Give it a default value of (0).\n",
    "   * n_reps: `int`, optional (default=5) - Number of independent replications to run.\n",
    "* The purpose of `my_multiple_replications` is to conduct `n_reps` independent replications of the model.\n",
    "* The function should return a list, array or dataframe of replication results.\n",
    "* After coding the function conduct 5 replications of the model.\n",
    "\n",
    "**Hints**\n",
    "* You need to `single_run` in a `for` loop\n",
    "* Alternatively you could make use of a list comprehension.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_multiple_replications(scenario, rc_period=1440, warm_up=0, n_reps=5):\n",
    "    #your code here ...\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example solution\n",
    "def my_multiple_replications(scenario, rc_period=1440, warm_up=0, n_reps=5):\n",
    "    '''\n",
    "    Perform multiple replications of the model.\n",
    "    \n",
    "    Params:\n",
    "    ------\n",
    "    scenario: Scenario\n",
    "        Parameters/arguments to configurethe model\n",
    "    \n",
    "    rc_period: float, optional (default=DEFAULT_RESULTS_COLLECTION_PERIOD)\n",
    "        results collection period.  \n",
    "        the number of minutes to run the model beyond warm up\n",
    "        to collect results\n",
    "    \n",
    "    warm_up: float, optional (default=0)\n",
    "        initial transient period.  no results are collected in this period\n",
    "\n",
    "    n_reps: int, optional (default=DEFAULT_N_REPS)\n",
    "        Number of independent replications to run.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "    '''\n",
    "    #implemented as list comprehension, but could also be for loop.\n",
    "    #note that I a have not set single_run's random_no_set parameter\n",
    "    #     this means that it produces a different result on each run\n",
    "    #   \n",
    "    results = [single_run(scenario, rc_period, warm_up) \n",
    "               for rep in range(n_reps)]\n",
    "    \n",
    "    #format and return results in a dataframe\n",
    "    df_results = pd.concat(results)\n",
    "    df_results.index = np.arange(1, len(df_results)+1)\n",
    "    df_results.index.name = 'rep'\n",
    "    return df_results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default scenario\n",
    "args = Scenario()\n",
    "\n",
    "print('Running multiple replications', end=' => ')\n",
    "results = my_multiple_replications(args, n_reps=5)\n",
    "print('done.\\n')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5: Controlling sampling across multiple replications\n",
    "\n",
    "The `single_run` function allows you to set a `random_no_set`.  In **exercise 1** you saw that the parameter controlled random sampling in a single run of the model. I.e. each random number set results in a unique set of sample combinations from each of the probability distributions in the model (e.g. arrivals and call duration).\n",
    "\n",
    "Your `my_multiple_replications` function has a lot of benefits.  However, it produces a different batch of replication values each time your run it because the code does not not set `random_no_set` on each replication.  \n",
    "\n",
    "To make this work you need to ensure that each replication uses a unique random no set.  An easy way to do this is to use the **replication number**.\n",
    "\n",
    "**Task**:\n",
    "* Modify your `my_multiple_replications` function\n",
    "* When calling the `single_run` function set the `random_no_set` to the current replication iteration number.\n",
    "* Run 5 replications of your model.\n",
    "* **Optional**: navigate to `hds_simpy/models/UrgentCareCallCentre` and read the code for `single_run()` and the class`Scenario`\n",
    "   * In particular, look at the methods `set_random_no_set()` and `init_sampling()` in the `Scenario` class\n",
    "   * (be careful not to change any code because might break the model!)\n",
    "\n",
    "**Questions:**\n",
    "* Try running your code multiple times. Does your code work?  Are your results repeatable?\n",
    "\n",
    "**Hints**:\n",
    "* Assuming you have implemented multiple replications in a `for` loop like the below then the you would use `rep` as your `random_no_set` in each call to `single_run()`\n",
    "\n",
    "```python\n",
    "for rep in range(n_reps):\n",
    "    pass\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here ... (recommend copy pasting your answer to ex 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example solution\n",
    "def my_multiple_replications(scenario, rc_period=1440, warm_up=0, n_reps=5):\n",
    "    '''\n",
    "    Perform multiple replications of the model.\n",
    "    \n",
    "    Params:\n",
    "    ------\n",
    "    scenario: Scenario\n",
    "        Parameters/arguments to configurethe model\n",
    "    \n",
    "    rc_period: float, optional (default=DEFAULT_RESULTS_COLLECTION_PERIOD)\n",
    "        results collection period.  \n",
    "        the number of minutes to run the model beyond warm up\n",
    "        to collect results\n",
    "    \n",
    "    warm_up: float, optional (default=0)\n",
    "        initial transient period.  no results are collected in this period\n",
    "\n",
    "    n_reps: int, optional (default=DEFAULT_N_REPS)\n",
    "        Number of independent replications to run.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "    '''\n",
    "    #I have now set single_run's random_no_set parameter\n",
    "    #this means that each replication has controlled reproducible sampling.\n",
    "    results = [single_run(scenario, rc_period, warm_up, random_no_set=rep) \n",
    "               for rep in range(n_reps)]\n",
    "    \n",
    "    #format and return results in a dataframe\n",
    "    df_results = pd.concat(results)\n",
    "    df_results.index = np.arange(1, len(df_results)+1)\n",
    "    df_results.index.name = 'rep'\n",
    "    return df_results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default scenario\n",
    "args = Scenario()\n",
    "\n",
    "print('Running multiple replications', end=' => ')\n",
    "results = my_multiple_replications(args, n_reps=5)\n",
    "print('done.\\n')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean results\n",
    "results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6: Estimating a warm-up period\n",
    "## Exercise 6.a Generating the warm-up replication data\n",
    "\n",
    "Your UrgentCareCallCentre model is a **non-terminating** system.  To estimate a warm-up period of the model you will use the **time series inspection approach**.  You will run 5 replications of the model and plot the cumulative mean performance measures at regular audit intervals (for example every 120 minutes).  With the time series inspection method you the choose a warm-up that allows the model to approximately settle to a steady state.\n",
    "\n",
    "There is a pre-written function `warmup_analysis` to help you with this task.  The function takes the following parameters:\n",
    "\n",
    "* `scenario`: a `Scenario` object.  Use the default settings\n",
    "* `rc_period`: float.  The result collection period\n",
    "* `interval`: float.  The interval between audits of the model. (default=120)\n",
    "* `n_reps`: int. The number of replications to run.\n",
    "\n",
    "You can import it via \n",
    "\n",
    "```python\n",
    "from hds_simpy.models.UrgentCareCallCentre import warmup_analysis\n",
    "```\n",
    "\n",
    "The function returns a python `dict`.  The dict has the following keys: 'operator_wait', 'nurse_wait', 'operator_util', 'nurse_util'. Each item in the dict is a `pd.DataFrame`.  For example, to access the 'nurse_wait' results use the following code:\n",
    "\n",
    "```python\n",
    "#assume results dict is called 'results'\n",
    "results['nurse_wait'].head()\n",
    "```\n",
    "\n",
    "> The warmup analysis code works just the same as `multiple_replications`.  The main difference is that \n",
    "a class called `WarmupAuditor` is used to periodically record the waiting times and utilisations.  Navigate to `hds_simpy/models/UrgentCareCallCentre` and checkout the function `warmup_single_run()` and the class `WarmupAuditor`.  The latter is a 'wrapper class' to UrgentCareCallCentre.\n",
    "\n",
    "**Task:**\n",
    "* Using the function provided and the code below run the model for \n",
    "    * 40 days (40 * 1440 minutes)\n",
    "    * 5 replications.\n",
    "    * with an audit interval of 120 minutes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hds_simpy.models.UrgentCareCallCentre import warmup_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#script\n",
    "#note this will take 5-30 seconds to run depending on your machine\n",
    "\n",
    "#run for 40 days\n",
    "RUN_LENGTH = 1440 * 40\n",
    "\n",
    "#run at least 5 replications, but more might be needed for noisy data\n",
    "N_REPS = 10\n",
    "\n",
    "#default scenario\n",
    "args = Scenario()\n",
    "\n",
    "#run warm up analysis for scenario\n",
    "print('Running warm-up analysis with replications. Please wait...', end=' => ')\n",
    "results = warmup_analysis(args, rc_period=RUN_LENGTH, n_reps=N_REPS)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['operator_wait'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6.b. Plotting the time series\n",
    "\n",
    "Now that you have your replication data you can plot the time series and inspect it.  To help you the function `time_series_inspection` has been provided.  Note that this function is specific to this model, but you could easily adapt for another problem with different performance measures.\n",
    "\n",
    "**Task**:\n",
    "* Run the code below and make a decision about a warm-up period.\n",
    "\n",
    "**Hints**\n",
    "* `time_series_inspection` takes a parameter called `warm_up`.  This will plot a vertical red line.  Use it to help you decided where to make the cut-off. \n",
    "* Try values in the range 150-250\n",
    "* If you think the data is too noisy go back and run 10 replications instead of 5 and then try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_inspection(results, warm_up=None):\n",
    "    '''\n",
    "    Time series inspection method\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    results: dict\n",
    "        The dict of results taken from warmup_analysis\n",
    "    '''\n",
    "    \n",
    "    #create the 4 chart areas to plot\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(12,9))\n",
    "    \n",
    "    #take the mean of the columns for each metric and plot\n",
    "    ax[0][0].plot(results['operator_wait'].mean(axis=1))\n",
    "    ax[0][1].plot(results['nurse_wait'].mean(axis=1))\n",
    "    ax[1][0].plot(results['operator_util'].mean(axis=1))\n",
    "    ax[1][1].plot(results['nurse_util'].mean(axis=1))\n",
    "\n",
    "    #set the label of each chart\n",
    "    ax[0][0].set_ylabel('operator_wait')\n",
    "    ax[0][1].set_ylabel('nurse_wait')\n",
    "    ax[1][0].set_ylabel('operator_util')\n",
    "    ax[1][1].set_ylabel('nurse_util')\n",
    "\n",
    "    if warm_up is not None:\n",
    "        #add warmup cut-off vertical line if one is specified\n",
    "        ax[0][0].axvline(x=warm_up, color='red', ls='--')\n",
    "        ax[0][1].axvline(x=warm_up, color='red', ls='--')\n",
    "        ax[1][0].axvline(x=warm_up, color='red', ls='--')\n",
    "        ax[1][1].axvline(x=warm_up, color='red', ls='--')\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this assumes you assigned the output of warmup_analysis to a varible 'results'\n",
    "fig, ax = time_series_inspection(results, warm_up=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6.c rerunning the model with warm up time \n",
    "Now that you have selected a warmup period you can rerun the model and delete the initial transient period.  To do this it is recommended you make use of the supplied function `multiple_replications`\n",
    "\n",
    "**Task:**\n",
    "* Use the code below to rerun the model.\n",
    "* Run 80 replications of your model.\n",
    "\n",
    "**Hints**\n",
    "* Notice that the you are now passing a warm-up period to `multiple_replications`.\n",
    "* You will use these replications in the next exercise so remember the name of the results variable.\n",
    "* Depending on your machine and the warm-up you have chosen it will take 60-90 seconds to run 100 replications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "############## MODIFICATION  ################################\n",
    "#set models warmup period\n",
    "AUDIT_INTERVAL = 120\n",
    "#set this to the value you selected e.g. between 150 and 250\n",
    "WARM_UP_INTERVALS = 170 \n",
    "#this converts you warmup interval into minutes.\n",
    "WARM_UP = WARM_UP_INTERVALS * AUDIT_INTERVAL\n",
    "##############################################################\n",
    "\n",
    "#results collection over a single day\n",
    "RC_PERIOD = 1440\n",
    "\n",
    "#number of replications\n",
    "N_REPS = 80\n",
    "\n",
    "#default scenario\n",
    "args = Scenario()\n",
    "\n",
    "#run multiple replications.\n",
    "print('Running multiple replications', end=' => ')\n",
    "replications  = multiple_replications(args, rc_period=RC_PERIOD, warm_up=WARM_UP,\n",
    "                                      n_reps=N_REPS)\n",
    "print('done.\\n')\n",
    "\n",
    "#show results summary rounded to 2dp\n",
    "replications.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the number of replications to run.\n",
    "\n",
    "You will now use the **confidence interval method** to select the number replications to run in order to get a good estimate the models mean performance.  The narrower the confidence interval the more precise our estimate of the mean. In general, the more replications you run the narrower the confidence interval. The method requires you to set a predefined width of the confidence interval.  In this course, we will make the somewhat arbitrary decision to opt for an interval that is 10% or 5% either side of the mean.\n",
    "\n",
    "A confidence interval is calculated as:\n",
    "\n",
    "$$ CI = \\overline{X} \\pm t_{n-1, \\alpha/2} \\dfrac{S}{\\sqrt{n}}$$\n",
    "\n",
    "\n",
    "where: \n",
    "\n",
    "* $\\overline{X}$ = mean of the output data from the replications\n",
    "* $S$ = standard deviation of the output data from the replications\n",
    "* $n$ = the number of replications\n",
    "* $t_{n-1, \\alpha/2}$ = value from the *t*-distribution with $n-1$ degrees of freedomand a significance level of $\\alpha/2$\n",
    "\n",
    "## Implementation in python\n",
    "\n",
    "The function `confidence_interval_method` is provided for you.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_interval_method(replications, alpha=0.05, desired_precision=0.05, \n",
    "                               min_rep=5, decimal_place=2):\n",
    "    '''\n",
    "    The confidence interval method for selecting the number of replications\n",
    "    to run in a simulation.\n",
    "    \n",
    "    Finds the smallest number of replications where the width of the confidence\n",
    "    interval is less than the desired_precision.  \n",
    "    \n",
    "    Returns both the number of replications and the full results dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    replications: arraylike\n",
    "        Array (e.g. np.ndarray or list) of replications of a performance metric\n",
    "        \n",
    "    alpha: float, optional (default=0.05)\n",
    "        procedure constructs a 100(1-alpha) confidence interval for the \n",
    "        cumulative mean.\n",
    "        \n",
    "    desired_precision: float, optional (default=0.05)\n",
    "        Desired mean deviation from confidence interval.\n",
    "        \n",
    "    min_rep: int, optional (default=5)\n",
    "        set to a integer > 0 and ignore all of the replications prior to it \n",
    "        when selecting the number of replications to run to achieve the desired\n",
    "        precision.  Useful when the number of replications returned does not\n",
    "        provide a stable precision below target.\n",
    "        \n",
    "    decimal_places: int, optional (default=2)\n",
    "        sets the number of decimal places of the returned dataframe containing\n",
    "        the results\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "        tuple: int, pd.DataFrame\n",
    "    \n",
    "    '''\n",
    "    n = len(replications)\n",
    "    cumulative_mean = [replications[0]]\n",
    "    running_var = [0.0]\n",
    "    for i in range(1, n):\n",
    "        cumulative_mean.append(cumulative_mean[i-1] + \\\n",
    "                       (replications[i] - cumulative_mean[i-1] ) / (i+1))\n",
    "        \n",
    "        #running biased variance\n",
    "        running_var.append(running_var[i-1] + (replications[i] \n",
    "                                               - cumulative_mean[i-1]) \\\n",
    "                            * (replications[i] - cumulative_mean[i]))\n",
    "        \n",
    "    #unbiased std dev = running_var / (n - 1)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        running_std = np.sqrt(running_var / np.arange(n))\n",
    "    \n",
    "    #half width of interval\n",
    "    dof = len(replications) - 1\n",
    "    t_value = t.ppf(1 - (alpha / 2),  dof)    \n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        std_error = running_std / np.sqrt(np.arange(1, n+1))\n",
    "        \n",
    "    half_width = t_value * std_error\n",
    "        \n",
    "    #upper and lower confidence interval\n",
    "    upper = cumulative_mean + half_width\n",
    "    lower = cumulative_mean - half_width\n",
    "    \n",
    "    #Mean deviation\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        deviation = (half_width / cumulative_mean) * 100\n",
    "    \n",
    "    #commbine results into a single dataframe\n",
    "    results = pd.DataFrame([replications, cumulative_mean, \n",
    "                            running_std, lower, upper, deviation]).T\n",
    "    results.columns = ['Mean', 'Cumulative Mean', 'Standard Deviation', \n",
    "                       'Lower Interval', 'Upper Interval', '% deviation']\n",
    "    results.index = np.arange(1, n+1)\n",
    "    results.index.name = 'replications'\n",
    "    \n",
    "    #get the smallest no. of reps where deviation is less than precision target\n",
    "    try:\n",
    "        n_reps = results.iloc[min_rep:].loc[results['% deviation'] \n",
    "                             <= desired_precision*100].iloc[0].name\n",
    "    except:\n",
    "        #no replications with desired precision\n",
    "        message = 'WARNING: the replications do not reach desired precision'\n",
    "        warnings.warn(message)\n",
    "        n_reps = -1 \n",
    "\n",
    "    \n",
    "    return n_reps, results.round(2)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: pass the replications to the method\n",
    "\n",
    "The function `confidence_interval_method` returns a tuple `(int, pandas.DataFrame)`.  The first element is the minimum number of replications required to achieve the precision (desired width of the interval).  The second, element is all of the data including the confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the method on the operator_wait replications\n",
    "n_reps, conf_ints = confidence_interval_method(replications['operator_wait'].to_numpy(),\n",
    "                                               desired_precision=0.05)\n",
    "\n",
    "#print out the min number of replications to achieve precision\n",
    "print(f'\\nminimum number of reps for 5% precision: {n_reps}\\n')\n",
    "\n",
    "#peek at table of results\n",
    "conf_ints.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Plot the results\n",
    "\n",
    "It is useful to look at the results visually to check if the confidence intervals converge or if the expand again later on.\n",
    "\n",
    "The function `plot_confidence_interval_method` has been provided to help.\n",
    "\n",
    "Run the code below to produce the plot.  Do you think it looks stable?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confidence_interval_method(n_reps, conf_ints, metric_name, \n",
    "                                    figsize=(12,4)):\n",
    "    '''\n",
    "    Plot the confidence intervals and cumulative mean\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    n_reps: int\n",
    "        minimum number of reps selected\n",
    "        \n",
    "    conf_ints: pandas.DataFrame\n",
    "       results of the `confidence_interval_method` function\n",
    "       \n",
    "    metric_name: str\n",
    "        Name of the performance measure\n",
    "        \n",
    "    figsize: tuple, optional (default=(12,4))\n",
    "        The size of the plot\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "        matplotlib.pyplot.axis\n",
    "    '''\n",
    "    #plot cumulative mean + lower/upper intervals\n",
    "    ax = conf_ints[['Cumulative Mean', 'Lower Interval', \n",
    "                         'Upper Interval']].plot(figsize=figsize)\n",
    "    #add the \n",
    "    ax.axvline(x=n_reps, ls='--', color='red')\n",
    "    \n",
    "    ax.set_ylabel(f'cumulative mean: {metric_name}')\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the confidence intervals\n",
    "ax = plot_confidence_interval_method(n_reps, conf_ints, \n",
    "                                     metric_name='operator_wait')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Look ahead\n",
    "\n",
    "Another good idea is to check the % deviation 10-20 replications ahead to check quantitatively that the 5% precision is maintained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick check if the % deviation remains below 5% for the next 10 reps?\n",
    "lookahead = 15\n",
    "conf_ints.iloc[n_reps-1:n_reps+lookahead]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Rerun the CI analysis\n",
    "\n",
    "You should find that the CI deviation exceeds 5% again after 36 replications.  Let's rerun `confidence_interval_method` and set the `min_rep` parameters to 36.  This means we will begin our checking at least at replication 36."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the method on the operator_wait replications\n",
    "n_reps, conf_ints = confidence_interval_method(replications['operator_wait'].to_numpy(),\n",
    "                                               desired_precision=0.05, min_rep=36)\n",
    "\n",
    "\n",
    "#print out the min number of replications to achieve precision\n",
    "print(f'\\nminimum number of reps for 5% precision: {n_reps}\\n')\n",
    "\n",
    "#plot the confidence intervals\n",
    "ax = plot_confidence_interval_method(n_reps, conf_ints, \n",
    "                                     metric_name='operator_wait')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Utilisation.\n",
    "\n",
    "The method is less useful for values very close to zero.  As the utilisation measures are between 0 and 1 it is recommended that you multiple the values by 100. For example, to handle operator utilisation you would use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the method on the opts util replications\n",
    "#We already know that we have to run > 50 reps so set min_rep parameter = 50.\n",
    "n_reps, conf_ints = confidence_interval_method(replications['ops_util'].to_numpy() * 100,\n",
    "                                               desired_precision=0.05, min_rep=50)\n",
    "\n",
    "print('Analysis of replications for operator utilisation...')\n",
    "\n",
    "#print out the min number of replications to achieve precision\n",
    "print(f'\\nminimum number of reps for 5% precision: {n_reps}\\n')\n",
    "\n",
    "#plot the confidence intervals\n",
    "ax = plot_confidence_interval_method(n_reps, conf_ints, \n",
    "                                     metric_name='ops_util')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7: Number of replications for nurse variables\n",
    "\n",
    "When selecting the number of replications you should repeat the analysis for all performance measures and select the highest value as your number of replications.\n",
    "\n",
    "**Task**:\n",
    "* Use the confidence interval method with the `nurse_wait` and `nurse_util` performance measures.\n",
    "\n",
    "**Questions:**\n",
    "* What number of replications would you choose for your model?\n",
    "\n",
    "**Hints:**\n",
    "* You don't need to rerun any replications.  You can reuse the replications you have already run.\n",
    "* You already know that you need to run at least 50 replications so set the `min_rep` parameter of `confidence_interval_method` to 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example answer\n",
    "\n",
    "#run the method on the nurse_wait replications\n",
    "n_reps, conf_ints = confidence_interval_method(replications['nurse_wait'].to_numpy(),\n",
    "                                               desired_precision=0.05, min_rep=50)\n",
    "\n",
    "print('Analysis of replications for nurse waiting time...')\n",
    "\n",
    "#print out the min number of replications to achieve precision\n",
    "print(f'\\nminimum number of reps for 5% precision: {n_reps}\\n')\n",
    "\n",
    "#plot the confidence intervals\n",
    "ax = plot_confidence_interval_method(n_reps, conf_ints, \n",
    "                                     metric_name='nurse_wait')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the method on the nurse_wait replications\n",
    "n_reps, conf_ints = confidence_interval_method(replications['nurse_util'].to_numpy() * 100,\n",
    "                                               desired_precision=0.05, min_rep=50)\n",
    "\n",
    "print('Analysis of replications for nurse waiting time...')\n",
    "\n",
    "#print out the min number of replications to achieve precision\n",
    "print(f'\\nminimum number of reps for 5% precision: {n_reps}\\n')\n",
    "\n",
    "#plot the confidence intervals\n",
    "ax = plot_confidence_interval_method(n_reps, conf_ints, \n",
    "                                     metric_name='nurse_util')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8: Scenario Analysis\n",
    "## Exercise 8a: Organising your code\n",
    "\n",
    "**Task**:\n",
    "\n",
    "* Complete the `get_scenarios` function below.  You should create the following scenarios:\n",
    "    * 1 additional operator\n",
    "    * 1 additional nurse\n",
    "    * A combination of the first two scenarios\n",
    "    \n",
    "**Hints:**:\n",
    "* The number of nurses and operators is controlled by the `Scenario` class attributes `n_nurses` and `n_operators`, respectively.  For example:\n",
    "\n",
    "```python\n",
    "#create scenario with an extra nurse\n",
    "scenario_1 = Scenario()\n",
    "scenario_1.n_nurses += 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task: complete this function\n",
    "\n",
    "def get_scenarios():\n",
    "    '''\n",
    "    Creates a dictionary object containing\n",
    "    objects of type `Scenario` to run.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Contains the scenarios for the model\n",
    "    '''\n",
    "    scenarios = {}\n",
    "    scenarios['base'] = Scenario()\n",
    "    \n",
    "    ########## MODIFICATION HERE ##########################\n",
    "    # your code here...\n",
    "    # scenarios['operator+1'] = ...\n",
    "    # scenarios['nurse+1'] = ...\n",
    "    # scenarios['operator+nurse'] = ...\n",
    "    \n",
    "    \n",
    "    #######################################################\n",
    "    \n",
    "    return scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example answer\n",
    "def get_scenarios():\n",
    "    '''\n",
    "    Creates a dictionary object containing\n",
    "    objects of type `Scenario` to run.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Contains the scenarios for the model\n",
    "    '''\n",
    "    scenarios = {}\n",
    "    scenarios['base'] = Scenario()\n",
    "    \n",
    "    ########## MODIFICATION HERE ##########################\n",
    "    # your code here...\n",
    "    scenarios['operator+1'] = Scenario()\n",
    "    scenarios['operator+1'].n_operators += 1\n",
    "    \n",
    "    scenarios['nurse+1'] = Scenario()\n",
    "    scenarios['nurse+1'].n_nurses += 1\n",
    "    \n",
    "    scenarios['operator+nurse'] = Scenario()\n",
    "    scenarios['operator+nurse'].n_operators += 1\n",
    "    scenarios['operator+nurse'].n_nurses += 1\n",
    "    \n",
    "    #######################################################\n",
    "    \n",
    "    return scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scenario_analysis(scenarios, rc_period, warm_up, n_reps):\n",
    "    '''\n",
    "    Run each of the scenarios for a specified results\n",
    "    collection period, warmup and replications.\n",
    "    \n",
    "    (note if you have lots of scenarios this may take several minutes)\n",
    "    '''\n",
    "    print('Scenario Analysis')\n",
    "    print(f'No. Scenario: {len(scenarios)}')\n",
    "    print(f'Replicatins: {n_reps}')\n",
    "    \n",
    "    \n",
    "    scenario_results = {}\n",
    "    for sc_name, scenario in scenarios.items():\n",
    "        \n",
    "        print(f'Running {sc_name}', end=' => ')\n",
    "        replications  = multiple_replications(scenario, rc_period=RC_PERIOD, \n",
    "                                              warm_up=warm_up,\n",
    "                                              n_reps=n_reps)\n",
    "        print('done.\\n')\n",
    "        \n",
    "        #save the results\n",
    "        scenario_results[sc_name] = replications\n",
    "    \n",
    "    print('Scenario analysis complete.')\n",
    "    return scenario_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#script to run model\n",
    "#note: for 4 scenarios and 50 reps this will take a few minutes.\n",
    "\n",
    "#set models warmup period\n",
    "AUDIT_INTERVAL = 120\n",
    "#set this to the value you selected e.g. between 150 and 250\n",
    "WARM_UP_INTERVALS = 170 \n",
    "#this converts you warmup interval into minutes.\n",
    "WARM_UP = WARM_UP_INTERVALS * AUDIT_INTERVAL\n",
    "\n",
    "#results collection over a single day\n",
    "RC_PERIOD = 1440\n",
    "\n",
    "#number of replications\n",
    "N_REPS = 51\n",
    "\n",
    "#get the scenarios\n",
    "scenarios = get_scenarios()\n",
    "\n",
    "#run the scenario analysis\n",
    "scenario_results = run_scenario_analysis(scenarios, RC_PERIOD, WARM_UP,\n",
    "                                         N_REPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a peek at the results for the 1st scenario\n",
    "scenario_results['operator+1'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8.b: Presenting the results\n",
    "\n",
    "There are always a lot of options to present your results.  A bare minimum is to present a simple table of results.\n",
    "\n",
    "The function `scenario_summary_frame` illustrates one way to combine mean results into a single dataframe.\n",
    "The script below it then renames the rows and columns to something more suitable to a report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scenario_summary_frame(scenario_results):\n",
    "    '''\n",
    "    Mean results for each performance measure by scenario\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    scenario_results: dict\n",
    "        dictionary of replications.  \n",
    "        Key identifies the performance measure\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "    '''\n",
    "    columns = []\n",
    "    summary = pd.DataFrame()\n",
    "    for sc_name, replications in scenario_results.items():\n",
    "        summary = pd.concat([summary, replications.mean()], axis=1)\n",
    "        columns.append(sc_name)\n",
    "\n",
    "    summary.columns = columns\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as well as rounding you may want to rename the cols/rows to \n",
    "#more readable alternatives.\n",
    "summary_frame = scenario_summary_frame(scenario_results)\n",
    "summary_frame.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic visualisation\n",
    "\n",
    "**Examples**:\n",
    "\n",
    "* Basic bar chart of the mean of a performance measure by scenario\n",
    "* Basic boxplot of a performance measure by scenario\n",
    "\n",
    "> In practice you would need to make better use of matplolib to visualise results.\n",
    "\n",
    "## a. Bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = summary_frame.T['nurse_wait'].plot.bar(figsize=(12,4))\n",
    "ax.set_ylabel('Waiting time for nurse');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Box and whisker plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess the data first\n",
    "\n",
    "def metric_by_scenario(select, scenario_results):\n",
    "    metric = pd.DataFrame()\n",
    "    columns = []\n",
    "    for sc_name, replications in scenario_results.items():\n",
    "        metric = pd.concat([metric, replications[select]], \n",
    "                           axis=1)\n",
    "        columns.append(sc_name)\n",
    "\n",
    "    metric.columns = columns\n",
    "    return metric\n",
    "\n",
    "\n",
    "metric_nw = metric_by_scenario('nurse_wait', \n",
    "                               scenario_results)\n",
    "\n",
    "metric_nu = metric_by_scenario('nurse_util',\n",
    "                               scenario_results)\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12,8), \n",
    "                       sharex=True)\n",
    "ax[0].boxplot(metric_nw.T);\n",
    "ax[1].boxplot(metric_nu.T);\n",
    "ax[0].set_ylabel('Mean Waiting time for nurse')\n",
    "ax[1].set_ylabel('Mean nurse utilisation');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
